{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22hBZbxx98IS"
   },
   "source": [
    "# Redes Convolucionadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo mnist - handwrite numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autor\n",
    "\n",
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importa módulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Versión de Tensorflow: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lee los datos desde tf.keras y los preprocesa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22hBZbxx98IS"
   },
   "outputs": [],
   "source": [
    "# apunta  los datos\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# lee los conjuntos de datos, los cuales vienen separados de antemano para entrenamiento y test\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# reshape para colocar los datos de entrenamiento en el fomato apropiado. Agrega una dimensión al final y  normaliza los datos\n",
    "training_images=training_images.reshape(60000, 28, 28, 1)\n",
    "training_images=training_images / 255.0\n",
    "# reshape para colocar los datos de test en el fomato apropiado. Agrega una dimensión al final y  normaliza los datos\n",
    "test_images = test_images.reshape(10000, 28, 28, 1)\n",
    "test_images=test_images/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muestra una imagen de entranamiento\n",
    "import matplotlib.pyplot as plt\n",
    "print(training_images[10,:,:,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label =' ,training_labels[10])\n",
    "plt.imshow(training_images[10,:,:,0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Capa 1: Conv2D con 32 filtros (kernels) de tamaño 3*3. Cada image viene en un tensor de tamaño 28*28*1. Los filtros son pasados por una f. de activaci+on 'relu'.\n",
    "2. Capa 2. MaxPooling. Reduce cada filtro. Toma regiones secuenciales 2*2 y los reduce tomando el máximo de cada región. No usa f. de activación nunca.\n",
    "\n",
    "<figure>\n",
    "<center>\n",
    "<img src=\"./Imagenes/maxpool.webp\" width=\"600\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Max pooling 2*2</p>\n",
    "</figcaption>\n",
    "</figure>\n",
    "\n",
    "3. Capa 3. Flatten. Toma todos los filtros resultantes  de la capa MaxPooling y los organiza como un único tensor unidimensional\n",
    "4. Capa 4. Dense. Recibe el tensor saliente de la capa Flatten y genera una salida en 128 unidades, usando activación *relu*\n",
    "5. Capa 5. Densa Recibe el tensor unidmensional de shape=128 t lo transforma en la salida de 10 unidades. Hay 10 clases. El predictor es al final transformado por la acticación *softmax* para obtener una distribución de la posible clase para la imagend e entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22hBZbxx98IS"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crea una clase derivada de tf.keras.callbacks.Callback \n",
    "\n",
    "Se usa para pasar funciones de control al algoritmo de estimación. Aquí la usaremos para el entrenamiento pare cuando se alcance un determinado accuracy con los datos de entrenamiento\n",
    "\n",
    "*tf.keras.callbacks.Callback* es una clase abstracta para permitir escribir métodos que actuan en el proceso de entranamiento o de test. Para detalles vea [tf.keras.callbacks.Callback](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('val_accuracy')>0.999):\n",
    "            print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "# crea una instancia de clase\n",
    "accu_callback = myCallback()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crea un checkpoint para guardar los pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "import os \n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"mnist_ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True, \n",
    "    monitor='val_accuracy', mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compila el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe como se pasan los callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrena el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "22hBZbxx98IS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 29s 609us/sample - loss: 1.0820e-06 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9880\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 30s 626us/sample - loss: 8.0284e-07 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9887\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 31s 641us/sample - loss: 5.6646e-07 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9883\n",
      "Epoch 4/20\n",
      "22080/48000 [============>.................] - ETA: 14s - loss: 3.9061e-07 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "\n",
    "#history = model.fit(training_images, training_labels, epochs=100, validation_split=0.2, batch_size=32,callbacks=[accu_callback, checkpoint_callback])\n",
    "history = model.fit(training_images, training_labels, epochs=20, validation_split=0.2, batch_size=64,callbacks=[accu_callback,checkpoint_callback ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalua el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gráficas de funciones de pérdida y accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "n_row = 1\n",
    "n_col = 2\n",
    "fig, ax = plt.subplots(n_row, n_col, sharex = False, sharey = False, figsize=(16,4))\n",
    "\n",
    "\n",
    "ax[0].plot(epochs, acc, 'r', label='Training accuracy')\n",
    "ax[0].plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "ax[0].legend(fontsize=12,loc=0)\n",
    "ax[0].set_title('Training and Validation Accuracy',fontsize=16)\n",
    "ax[0].set_ylabel('measure',fontsize=14)\n",
    "ax[0].set_xlabel('epoch', fontsize = 14)\n",
    "ax[0].set_xlim([1, len(acc)])\n",
    "\n",
    "ax[1].plot(epochs, loss, 'r', label='Training Loss')\n",
    "ax[1].plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "ax[1].legend(fontsize=12)\n",
    "ax[1].set_title('Training and Validation Loss',fontsize=16)\n",
    "ax[1].set_ylabel('measure',fontsize=14)\n",
    "ax[1].set_xlabel('epoch', fontsize = 14)\n",
    "ax[1].set_xlim([1, len(acc)])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga los pesos del mejor modelo obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "#model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalua el modelo con los dato de prueba (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muestra de algunas predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula las clases predichas las probabilidades calculadas por softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_classes(test_images)\n",
    "prob = model.predict_proba(test_images)\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7 7\n",
      "1 2 2\n",
      "2 1 1\n",
      "3 0 0\n",
      "4 4 4\n",
      "5 1 1\n",
      "6 4 4\n",
      "7 9 9\n",
      "8 5 5\n",
      "9 9 9\n",
      "10 0 0\n",
      "11 6 6\n",
      "12 9 9\n",
      "13 0 0\n",
      "14 1 1\n",
      "15 5 5\n",
      "16 9 9\n",
      "17 7 7\n",
      "18 5 3\n",
      "19 4 4\n",
      "20 9 9\n",
      "21 6 6\n",
      "22 6 6\n",
      "23 5 5\n",
      "24 4 4\n",
      "25 0 0\n",
      "26 7 7\n",
      "27 4 4\n",
      "28 0 0\n",
      "29 1 1\n",
      "30 3 3\n",
      "31 1 1\n",
      "32 3 3\n",
      "33 4 4\n",
      "34 7 7\n",
      "35 2 2\n",
      "36 7 7\n",
      "37 1 1\n",
      "38 2 2\n",
      "39 1 1\n",
      "40 1 1\n",
      "41 7 7\n",
      "42 4 4\n",
      "43 2 2\n",
      "44 3 3\n",
      "45 5 5\n",
      "46 1 1\n",
      "47 2 2\n",
      "48 4 4\n",
      "49 4 4\n",
      "50 6 6\n",
      "51 3 3\n",
      "52 5 5\n",
      "53 5 5\n",
      "54 6 6\n",
      "55 0 0\n",
      "56 4 4\n",
      "57 1 1\n",
      "58 9 9\n",
      "59 5 5\n",
      "60 7 7\n",
      "61 8 8\n",
      "62 9 9\n",
      "63 3 3\n",
      "64 7 7\n",
      "65 4 4\n",
      "66 6 6\n",
      "67 4 4\n",
      "68 3 3\n",
      "69 0 0\n",
      "70 7 7\n",
      "71 0 0\n",
      "72 2 2\n",
      "73 9 9\n",
      "74 1 1\n",
      "75 7 7\n",
      "76 3 3\n",
      "77 2 2\n",
      "78 9 9\n",
      "79 7 7\n",
      "80 7 7\n",
      "81 6 6\n",
      "82 2 2\n",
      "83 7 7\n",
      "84 8 8\n",
      "85 4 4\n",
      "86 7 7\n",
      "87 3 3\n",
      "88 6 6\n",
      "89 1 1\n",
      "90 3 3\n",
      "91 6 6\n",
      "92 9 9\n",
      "93 3 3\n",
      "94 1 1\n",
      "95 4 4\n",
      "96 1 1\n",
      "97 7 7\n",
      "98 6 6\n",
      "99 9 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(100):\n",
    "    print (i, preds[i], test_labels[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imagen 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label =' ,training_labels[10])\n",
    "plt.imshow(training_images[10,:,:,0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detección de malas predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_pred=[]\n",
    "for i in range (len(preds)):\n",
    "    if preds[i]!=test_labels[i]:\n",
    "        bad_pred.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18,\n",
       " 321,\n",
       " 340,\n",
       " 445,\n",
       " 659,\n",
       " 740,\n",
       " 882,\n",
       " 883,\n",
       " 938,\n",
       " 965,\n",
       " 1014,\n",
       " 1039,\n",
       " 1156,\n",
       " 1182,\n",
       " 1226,\n",
       " 1232,\n",
       " 1242,\n",
       " 1247,\n",
       " 1319,\n",
       " 1378,\n",
       " 1393,\n",
       " 1459,\n",
       " 1530,\n",
       " 1621,\n",
       " 1678,\n",
       " 1686,\n",
       " 1709,\n",
       " 1717,\n",
       " 1790,\n",
       " 1901,\n",
       " 1955,\n",
       " 2035,\n",
       " 2070,\n",
       " 2118,\n",
       " 2130,\n",
       " 2135,\n",
       " 2293,\n",
       " 2387,\n",
       " 2414,\n",
       " 2437,\n",
       " 2488,\n",
       " 2597,\n",
       " 2654,\n",
       " 2896,\n",
       " 2921,\n",
       " 2927,\n",
       " 2953,\n",
       " 3060,\n",
       " 3073,\n",
       " 3206,\n",
       " 3225,\n",
       " 3422,\n",
       " 3451,\n",
       " 3503,\n",
       " 3520,\n",
       " 3558,\n",
       " 3597,\n",
       " 3727,\n",
       " 3767,\n",
       " 3778,\n",
       " 3796,\n",
       " 3808,\n",
       " 3906,\n",
       " 4140,\n",
       " 4176,\n",
       " 4201,\n",
       " 4248,\n",
       " 4443,\n",
       " 4578,\n",
       " 4740,\n",
       " 4807,\n",
       " 4814,\n",
       " 4823,\n",
       " 4860,\n",
       " 5331,\n",
       " 5634,\n",
       " 5887,\n",
       " 5937,\n",
       " 5955,\n",
       " 6555,\n",
       " 6571,\n",
       " 6576,\n",
       " 6597,\n",
       " 8094,\n",
       " 8325,\n",
       " 8408,\n",
       " 9009,\n",
       " 9015,\n",
       " 9019,\n",
       " 9587,\n",
       " 9634,\n",
       " 9642,\n",
       " 9664,\n",
       " 9679,\n",
       " 9698,\n",
       " 9729,\n",
       " 9768,\n",
       " 9792,\n",
       " 9839,\n",
       " 9982]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label =' ,training_labels[bad_pred[2]], 'prediction= ',preds[bad_pred[2]])\n",
    "plt.imshow(training_images[bad_pred[2],:,:,0],cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Convolution_Example.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/lmoroney/dlaicourse/blob/master/Exercises/Exercise%203%20-%20Convolutions/Exercise%203%20-%20Answer.ipynb",
     "timestamp": 1572909835406
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
