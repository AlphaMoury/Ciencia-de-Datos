{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Generativas Adversarias (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Rowel Atiesa, Advanced Deep Learning with Tensorflow 2 and Keras, second ed., Pack, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una red generativa adversaria (GAN) es análogo a un escenario falsificador (generador) – policia (discriminador)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"./Imagenes/ladron.png\" width=\"500\" height=\"400\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Generador y discriminador de una GAN </p>\n",
    "</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En la academia, al policía se le enseña cómo determinar si un billete de un dólar es genuino o falso. \n",
    "\n",
    "Muestras de billetes reales en dólares del el banco y el dinero falso del falsificador se usan para entrenar a la policía. \n",
    "\n",
    "Sin embargo, de vez en cuando, el falsificador intentará fingir que imprimió dólares reales.\n",
    "\n",
    "\n",
    "Este proceso continúa indefinidamente, pero llegará a un punto donde el el falsificador ha dominado la creación de dinero falso en la medida en que las falsificaciones son indistinguibles del dinero real, incluso para los policías más entrenados.\n",
    "\n",
    "El falsificador puede imprimir infinitamente billetes de dólar sin ser atrapado por el policía ya que ya no son identificables como falsificados. \n",
    "\n",
    "Técnicamente el proceso se ve como sigue:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"./Imagenes/Gan_esquema.png\" width=\"500\" height=\"400\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Esquema de una GAN </p>\n",
    "</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La entrada del discriminador será datos reales o sintetizados. \n",
    "\n",
    "\n",
    "El discriminador recibe  muestras de datos genuinosy ,muestras  de datos falsos provienen que provienen del generador. \n",
    "\n",
    "\n",
    "Los datos válidos están etiquetados como 1.0 (es decir, un 100% de probabilidad de ser real), mientras que todos los\n",
    "los datos sintetizados están etiquetados como 0.0 (es decir, un 0% de probabilidad de ser real). \n",
    "\n",
    "\n",
    "E el proceso de etiquetado está automatizado, por lo que las GAN todavía consideran modelos de aprendizaje no supervisado.\n",
    "\n",
    "\n",
    "El objetivo del discriminador es aprender a  distinguir datos reales de datos falsos. Durante esta parte del entrenamiento de la GAN, solo Los parámetros del discriminador serán actualizados.\n",
    "\n",
    "El discriminador es  un clasificador binario típico y será entrenado para predecir en un rango de 0.0 a 1.0 en valores de confianza  tan cerca de 0.0 o 1.0 como sea posible, según reciba un dato falso o uno real.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La entrada al generador es ruido, y la salida son datos sintetizados. \n",
    "\n",
    "A intervalos regulares, el generador fingirá que su salida son datos genuinos y le pedirá a la GAN que lo etiquete como 1.0. Cuando los datos falsos se presentan al discriminador, naturalmente se clasificará como falso con una etiqueta cercana a 0.0.\n",
    "\n",
    "El optimizador calcula las actualizaciones de parámetros del generador en función de lo presentado\n",
    "etiqueta (es decir, 1.0). También tiene en cuenta su propia predicción cuando se entrena con esta nueva información. \n",
    "\n",
    "En otras palabras, el discriminador tiene algunas dudas con respecto a su predicción, y así, la GAN toma eso en consideración."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes competitivas o colaborativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the whole process is akin to two networks competing with one another\n",
    "while still cooperating at the same time. When the GAN training converges, the end\n",
    "result is a generator that can synthesize data that appears genuine. The discriminator\n",
    "thinks this synthesized data is real or with a label near 1.0, which means the\n",
    "discriminator can then be discarded. The generator part will be useful in producing\n",
    "meaningful outputs from arbitrary noise inputs.\n",
    "\n",
    "En general, todo el proceso es similar a dos redes que compiten entre sí\n",
    "mientras sigue cooperando al mismo tiempo. Cuando el entrenamiento de GAN converge, al final \n",
    "el resultado es un generador que puede sintetizar datos que parecen genuinos. \n",
    "\n",
    "El discriminador piensa que estos datos sintetizados son reales o con una etiqueta cercana a 1.0, lo que significa que\n",
    "El discriminador puede ser descartado. La parte del generador será útil para producir salidas significativas de entradas de ruido arbitrarias.\n",
    "\n",
    "La siguiente imagen describe el proceso de entrenamiento de una GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"./Imagenes/GAN_trainig.png\" width=\"500\" height=\"400\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Esquema de entrnamiento de una GAN </p>\n",
    "</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains DCGAN on MNIST using Keras\n",
    "\n",
    "DCGAN is a Generative Adversarial Network (GAN) using CNN.\n",
    "The generator tries to fool the discriminator by generating fake images.\n",
    "The discriminator learns to discriminate real from fake images.\n",
    "The generator + discriminator form an adversarial network.\n",
    "DCGAN trains the discriminator and adversarial networks alternately.\n",
    "During training, not only the discriminator learns to distinguish real from\n",
    "fake images, it also coaches the generator part of the adversarial on how\n",
    "to improve its ability to generate fake images.\n",
    "\n",
    "[1] Radford, Alec, Luke Metz, and Soumith Chintala.\n",
    "\"Unsupervised representation learning with deep convolutional\n",
    "generative adversarial networks.\" arXiv preprint arXiv:1511.06434 (2015).\n",
    "'''\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.layers import Activation, Dense, Input\n",
    "from tensorflow.keras.layers import Conv2D, Flatten\n",
    "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(inputs, image_size):\n",
    "    \"\"\"Build a Generator Model\n",
    "\n",
    "    Stack of BN-ReLU-Conv2DTranpose to generate fake images\n",
    "    Output activation is sigmoid.  Sigmoid converges easily.\n",
    "\n",
    "    Arguments:\n",
    "        inputs (Layer): Input layer of the generator \n",
    "            the z-vector)\n",
    "        image_size (tensor): Target size of one side\n",
    "            (assuming square image)\n",
    "\n",
    "    Returns:\n",
    "        generator (Model): Generator Model\n",
    "    \"\"\"\n",
    "\n",
    "    image_resize = image_size // 4\n",
    "    # network parameters \n",
    "    kernel_size = 5\n",
    "    layer_filters = [128, 64, 32, 1]\n",
    "\n",
    "    x = Dense(image_resize * image_resize * layer_filters[0])(inputs)\n",
    "    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n",
    "\n",
    "    for filters in layer_filters:\n",
    "        # first two convolution layers use strides = 2\n",
    "        # the last two use strides = 1\n",
    "        if filters > layer_filters[-2]:\n",
    "            strides = 2\n",
    "        else:\n",
    "            strides = 1\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Conv2DTranspose(filters=filters,\n",
    "                            kernel_size=kernel_size,\n",
    "                            strides=strides,\n",
    "                            padding='same')(x)\n",
    "\n",
    "    x = Activation('sigmoid')(x)\n",
    "    generator = Model(inputs, x, name='generator')\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{LeakyReLU}(x) = \\begin{cases} x &\\text{ si } x>0\\\\\n",
    "\\alpha x, \\hspace{3mm}0 <\\alpha < 1 &\\text{ si } x\\le 0 \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(inputs):\n",
    "    \"\"\"Build a Discriminator Model\n",
    "\n",
    "    Stack of LeakyReLU-Conv2D to discriminate real from fake.\n",
    "    The network does not converge with BN so it is not used here\n",
    "    unlike in [1] or original paper.\n",
    "\n",
    "    Arguments:\n",
    "        inputs (Layer): Input layer of the discriminator (the image)\n",
    "\n",
    "    Returns:\n",
    "        discriminator (Model): Discriminator Model\n",
    "    \"\"\"\n",
    "    kernel_size = 5\n",
    "    layer_filters = [32, 64, 128, 256]\n",
    "\n",
    "    x = inputs\n",
    "    for filters in layer_filters:\n",
    "        # first 3 convolution layers use strides = 2\n",
    "        # last one uses strides = 1\n",
    "        if filters == layer_filters[-1]:\n",
    "            strides = 1\n",
    "        else:\n",
    "            strides = 2\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        x = Conv2D(filters=filters,\n",
    "                   kernel_size=kernel_size,\n",
    "                   strides=strides,\n",
    "                   padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1)(x)\n",
    "    x = Activation('sigmoid')(x)\n",
    "    discriminator = Model(inputs, x, name='discriminator')\n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(models, x_train, params):\n",
    "    \"\"\"Train the Discriminator and Adversarial Networks\n",
    "\n",
    "    Alternately train Discriminator and Adversarial networks by batch.\n",
    "    Discriminator is trained first with properly real and fake images.\n",
    "    Adversarial is trained next with fake images pretending to be real\n",
    "    Generate sample images per save_interval.\n",
    "\n",
    "    Arguments:\n",
    "        models (list): Generator, Discriminator, Adversarial models\n",
    "        x_train (tensor): Train images\n",
    "        params (list) : Networks parameters\n",
    "\n",
    "    \"\"\"\n",
    "    # the GAN component models\n",
    "    generator, discriminator, adversarial = models\n",
    "    # network parameters\n",
    "    batch_size, latent_size, train_steps, model_name = params\n",
    "    # the generator image is saved every 500 steps\n",
    "    save_interval = 500\n",
    "    # noise vector to see how the generator output evolves during training\n",
    "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n",
    "    # number of elements in train dataset\n",
    "    train_size = x_train.shape[0]\n",
    "    for i in range(train_steps):\n",
    "        # train the discriminator for 1 batch\n",
    "        # 1 batch of real (label=1.0) and fake images (label=0.0)\n",
    "        # randomly pick real images from dataset\n",
    "        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n",
    "        real_images = x_train[rand_indexes]\n",
    "        # generate fake images from noise using generator \n",
    "        # generate noise using uniform distribution\n",
    "        noise = np.random.uniform(-1.0,\n",
    "                                  1.0,\n",
    "                                  size=[batch_size, latent_size])\n",
    "        # generate fake images\n",
    "        fake_images = generator.predict(noise)\n",
    "        # real + fake images = 1 batch of train data\n",
    "        x = np.concatenate((real_images, fake_images))\n",
    "        # label real and fake images\n",
    "        # real images label is 1.0\n",
    "        y = np.ones([2 * batch_size, 1])\n",
    "        # fake images label is 0.0\n",
    "        y[batch_size:, :] = 0.0\n",
    "        # train discriminator network, log the loss and accuracy\n",
    "        loss, acc = discriminator.train_on_batch(x, y)\n",
    "        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
    "\n",
    "        # train the adversarial network for 1 batch\n",
    "        # 1 batch of fake images with label=1.0\n",
    "        # since the discriminator weights \n",
    "        # are frozen in adversarial network\n",
    "        # only the generator is trained\n",
    "        # generate noise using uniform distribution\n",
    "        noise = np.random.uniform(-1.0,\n",
    "                                  1.0, \n",
    "                                  size=[batch_size, latent_size])\n",
    "        # label fake images as real or 1.0\n",
    "        y = np.ones([batch_size, 1])\n",
    "        # train the adversarial network \n",
    "        # note that unlike in discriminator training, \n",
    "        # we do not save the fake images in a variable\n",
    "        # the fake images go to the discriminator input of the adversarial\n",
    "        # for classification\n",
    "        # log the loss and accuracy\n",
    "        loss, acc = adversarial.train_on_batch(noise, y)\n",
    "        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n",
    "        print(log)\n",
    "        if (i + 1) % save_interval == 0:\n",
    "            # plot generator images on a periodic basis\n",
    "            plot_images(generator,\n",
    "                        noise_input=noise_input,\n",
    "                        show=False,\n",
    "                        step=(i + 1),\n",
    "                        model_name=model_name)\n",
    "   \n",
    "    # save the model after training the generator\n",
    "    # the trained generator can be reloaded for \n",
    "    # future MNIST digit generation\n",
    "    generator.save(model_name + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(generator,\n",
    "                noise_input,\n",
    "                show=False,\n",
    "                step=0,\n",
    "                model_name=\"gan\"):\n",
    "    \"\"\"Generate fake images and plot them\n",
    "\n",
    "    For visualization purposes, generate fake images\n",
    "    then plot them in a square grid\n",
    "\n",
    "    Arguments:\n",
    "        generator (Model): The Generator Model for \n",
    "            fake images generation\n",
    "        noise_input (ndarray): Array of z-vectors\n",
    "        show (bool): Whether to show plot or not\n",
    "        step (int): Appended to filename of the save images\n",
    "        model_name (string): Model name\n",
    "\n",
    "    \"\"\"\n",
    "    os.makedirs(model_name, exist_ok=True)\n",
    "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
    "    images = generator.predict(noise_input)\n",
    "    plt.figure(figsize=(2.2, 2.2))\n",
    "    num_images = images.shape[0]\n",
    "    image_size = images.shape[1]\n",
    "    rows = int(math.sqrt(noise_input.shape[0]))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(rows, rows, i + 1)\n",
    "        image = np.reshape(images[i], [image_size, image_size])\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(filename)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train_models():\n",
    "    # load MNIST dataset\n",
    "    (x_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # reshape data for CNN as (28, 28, 1) and normalize\n",
    "    image_size = x_train.shape[1]\n",
    "    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "\n",
    "    model_name = \"dcgan_mnist\"\n",
    "    # network parameters\n",
    "    # the latent or z vector is 100-dim\n",
    "    latent_size = 100\n",
    "    batch_size = 64\n",
    "    train_steps = 40000\n",
    "    lr = 2e-4\n",
    "    decay = 6e-8\n",
    "    input_shape = (image_size, image_size, 1)\n",
    "\n",
    "    # build discriminator model\n",
    "    inputs = Input(shape=input_shape, name='discriminator_input')\n",
    "    discriminator = build_discriminator(inputs)\n",
    "    # [1] or original paper uses Adam, \n",
    "    # but discriminator converges easily with RMSprop\n",
    "    optimizer = RMSprop(lr=lr, decay=decay)\n",
    "    discriminator.compile(loss='binary_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "    discriminator.summary()\n",
    "\n",
    "    # build generator model\n",
    "    input_shape = (latent_size, )\n",
    "    inputs = Input(shape=input_shape, name='z_input')\n",
    "    generator = build_generator(inputs, image_size)\n",
    "    generator.summary()\n",
    "\n",
    "    # build adversarial model\n",
    "    optimizer = RMSprop(lr=lr * 0.5, decay=decay * 0.5)\n",
    "    # freeze the weights of discriminator during adversarial training\n",
    "    discriminator.trainable = False\n",
    "    # adversarial = generator + discriminator\n",
    "    adversarial = Model(inputs, \n",
    "                        discriminator(generator(inputs)),\n",
    "                        name=model_name)\n",
    "    adversarial.compile(loss='binary_crossentropy',\n",
    "                        optimizer=optimizer,\n",
    "                        metrics=['accuracy'])\n",
    "    adversarial.summary()\n",
    "\n",
    "    # train discriminator and adversarial networks\n",
    "    models = (generator, discriminator, adversarial)\n",
    "    params = (batch_size, latent_size, train_steps, model_name)\n",
    "    train(models, x_train, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generator(generator):\n",
    "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
    "    plot_images(generator,\n",
    "                noise_input=noise_input,\n",
    "                show=True,\n",
    "                model_name=\"test_outputs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
