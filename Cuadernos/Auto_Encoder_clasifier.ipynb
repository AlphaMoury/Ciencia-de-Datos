{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'> Auto Encoders</h1>\n",
    "\n",
    "<h3>Autor</h3>\n",
    "\n",
    "1. Alvaro Mauricio Montenegro DÃ­az, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "\n",
    "<h3>Fork</h3>\n",
    "\n",
    "<h3>Referencias</h3>\n",
    "\n",
    "1. [Arvin Singh Kushwaha](https://towardsdatascience.com/how-to-make-an-autoencoder-2f2d99cd5103)\n",
    "2. [Gertjan vander Burg](https://gertjanvandenburg.com/blog/autoencoder/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Autoencoder with Classifier\n",
    "'''\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Activation, Dense, Dropout, Input, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Reshape, Conv2DTranspose, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "num_labels = np.amax(y_train) + 1\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "x_test = np.reshape(x_test, [-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# Network parameters\n",
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "pool_size = 2\n",
    "dropout = 0.4\n",
    "filters = 16\n",
    "latent_dim = 16\n",
    "\n",
    "# Build the autoencoder model\n",
    "# First build the encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "# Stack of BN-ReLU-Conv2D-MaxPooling blocks\n",
    "for i in range(2):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    filters = filters * 2\n",
    "    x = Conv2D(filters=filters, kernel_size=kernel_size,\n",
    "               padding='same')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "# Shape info needed to build decoder model\n",
    "shape = x.shape.as_list()\n",
    "\n",
    "# Generate a 16-dim latent vector\n",
    "x = Flatten()(x)\n",
    "latent = Dense(latent_dim, name='latent_vector')(x)\n",
    "\n",
    "# Instantiate encoder model\n",
    "encoder = Model(inputs, latent, name='encoder')\n",
    "encoder.summary()\n",
    "plot_model(encoder, to_file='classifier-encoder.png', show_shapes=True)\n",
    "\n",
    "# Build the Decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='decoder_input')\n",
    "x = Dense(shape[1]*shape[2]*shape[3])(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "\n",
    "# Stack of BN-ReLU-Transposed Conv2D-UpSampling blocks\n",
    "for i in range(2):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2DTranspose(filters=filters, kernel_size=kernel_size,\n",
    "                        padding='same')(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    filters = int(filters / 2)\n",
    "\n",
    "x = Conv2DTranspose(filters=1, kernel_size=kernel_size,\n",
    "                    padding='same')(x)\n",
    "\n",
    "outputs = Activation('sigmoid', name='decoder_output')(x)\n",
    "\n",
    "# Instantiate Decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()\n",
    "plot_model(decoder, to_file='classifier-decoder.png', show_shapes=True)\n",
    "\n",
    "# Classifier Model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='classifier_input')\n",
    "x = Dense(512)(latent_inputs)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(256)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(num_labels)(x)\n",
    "classifier_outputs = Activation('softmax', name='classifier_output')(x)\n",
    "classifier = Model(latent_inputs, classifier_outputs, name='classifier')\n",
    "classifier.summary()\n",
    "plot_model(classifier, to_file='classifier.png', show_shapes=True)\n",
    "\n",
    "# Autoencoder = Encoder + Classifier/Decoder\n",
    "# Instantiate autoencoder model\n",
    "autoencoder = Model(inputs,\n",
    "                    [classifier(encoder(inputs)), decoder(encoder(inputs))],\n",
    "                    name='autodecoder')\n",
    "autoencoder.summary()\n",
    "plot_model(autoencoder, to_file='classifier-autoencoder.png', show_shapes=True)\n",
    "\n",
    "# Mean Square Error (MSE) loss function, Adam optimizer\n",
    "autoencoder.compile(loss=['categorical_crossentropy', 'mse'],\n",
    "                    optimizer='adam',\n",
    "                    metrics=['accuracy', 'mse'])\n",
    "\n",
    "# Train the autoencoder for 1 epoch\n",
    "autoencoder.fit(x_train, [y_train, x_train],\n",
    "                validation_data=(x_test, [y_test, x_test]),\n",
    "                epochs=2, batch_size=batch_size,\n",
    "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n",
    "\n",
    "# Predict the Autoencoder output from test data\n",
    "y_predicted, x_decoded = autoencoder.predict(x_test)\n",
    "print(np.argmax(y_predicted[:8], axis=1))\n",
    "\n",
    "# Display the 1st 8 input and decoded images\n",
    "imgs = np.concatenate([x_test[:8], x_decoded[:8]])\n",
    "imgs = imgs.reshape((4, 4, image_size, image_size))\n",
    "imgs = np.vstack([np.hstack(i) for i in imgs])\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.title('Input: 1st 2 rows, Decoded: last 2 rows')\n",
    "plt.imshow(imgs, interpolation='none', cmap='gray')\n",
    "plt.savefig('input_and_decoded.png')\n",
    "plt.show()\n",
    "\n",
    "# latent = encoder.predict(x_test)\n",
    "# print(\"Variance:\", K.var(latent))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
