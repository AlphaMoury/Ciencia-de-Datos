{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a la API Keras functional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autor\n",
    "\n",
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [Documentación de Keras](https://keras.io/getting-started/sequential-model-guide/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La API funcional de Keras se guía por los siguientes dos conceptos:\n",
    "\n",
    "1. Una capa es una instancia que acepta un tensor como argumento. La salida de una capa es otro tensor. Para construir un modelo, las instancias de capa son objetos que están encadenados entre sí a través de los tensores de entrada y salida. Esto tendrá un resultado final similar al apilamiento de varias capas en el modelo secuencial. Sin embargo, el uso de instancias de capa facilita que los modelos tengan entradas y salidas auxiliares o múltiples, ya que la entrada / salida de cada capa será fácilmente accesible.\n",
    "\n",
    "2. Un modelo es una función entre uno o más tensores de entrada y tensores de salida. Entre la entrada y la salida del modelo, los tensores son las instancias de capa que están encadenados entre sí por los tensores de entrada y salida de la capa. Un modelo es, por lo tanto, una función de una o más capas de entrada y una o más capas de salida. La instancia del modelo formaliza el gráfico computacional sobre cómo fluyen los datos de entrada (s) a salida (s).\n",
    "\n",
    "\n",
    "Para ilustrar, la API funcional, una capa convolucional bidimensional, Conv2D, con 32 filtros y con *x* como tensor de entrada de capa, y como tensor de salida de capa se puede escribir como:\n",
    "\n",
    "y = Conv2D(32)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sparse label to categorical\n",
    "num_labels = len(np.unique(y_train))\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape and normalize input images\n",
    "image_size = x_train.shape[1]\n",
    "x_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
    "x_test = np.reshape(x_test,[-1, image_size, image_size, 1])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network parameters\n",
    "input_shape = (image_size, image_size, 1)\n",
    "batch_size = 128\n",
    "kernel_size = 3\n",
    "filters = 64\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use functional API to build cnn layers\n",
    "inputs = Input(shape=input_shape)\n",
    "y = Conv2D(filters=filters,\n",
    "           kernel_size=kernel_size,\n",
    "           activation='relu')(inputs)\n",
    "y = MaxPooling2D()(y) # pool_size=2, por defecto\n",
    "y = Conv2D(filters=filters,\n",
    "           kernel_size=kernel_size,\n",
    "           activation='relu')(y)\n",
    "y = MaxPooling2D()(y)\n",
    "y = Conv2D(filters=filters,\n",
    "           kernel_size=kernel_size,\n",
    "           activation='relu')(y)\n",
    "# image to vector before connecting to dense layer\n",
    "y = Flatten()(y)\n",
    "# dropout regularization\n",
    "y = Dropout(dropout)(y)\n",
    "outputs = Dense(num_labels, activation='softmax')(y)\n",
    "# build the model by supplying inputs/outputs\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                5770      \n",
      "=================================================================\n",
      "Total params: 80,266\n",
      "Trainable params: 80,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# network model in text\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier loss, Adam optimizer, classifier accuracy\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_size=0.2\n",
    "# validation_split=validation_size\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 85s 1ms/sample - loss: 0.2740 - accuracy: 0.9135 - val_loss: 0.0565 - val_accuracy: 0.9816\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 83s 1ms/sample - loss: 0.0721 - accuracy: 0.9780 - val_loss: 0.0369 - val_accuracy: 0.9882\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0525 - accuracy: 0.9838 - val_loss: 0.0322 - val_accuracy: 0.9894\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 95s 2ms/sample - loss: 0.0422 - accuracy: 0.9868 - val_loss: 0.0274 - val_accuracy: 0.9904\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 91s 2ms/sample - loss: 0.0363 - accuracy: 0.9879 - val_loss: 0.0259 - val_accuracy: 0.9915\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0305 - accuracy: 0.9906 - val_loss: 0.0272 - val_accuracy: 0.9908\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0265 - accuracy: 0.9915 - val_loss: 0.0284 - val_accuracy: 0.9909\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0237 - accuracy: 0.9921 - val_loss: 0.0262 - val_accuracy: 0.9914\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0219 - accuracy: 0.9926 - val_loss: 0.0264 - val_accuracy: 0.9909\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 90s 1ms/sample - loss: 0.0200 - accuracy: 0.9934 - val_loss: 0.0220 - val_accuracy: 0.9934\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0181 - accuracy: 0.9941 - val_loss: 0.0281 - val_accuracy: 0.9922\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0166 - accuracy: 0.9945 - val_loss: 0.0237 - val_accuracy: 0.9922\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 95s 2ms/sample - loss: 0.0152 - accuracy: 0.9947 - val_loss: 0.0220 - val_accuracy: 0.9937\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 88s 1ms/sample - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.0220 - val_accuracy: 0.9933\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 90s 1ms/sample - loss: 0.0126 - accuracy: 0.9955 - val_loss: 0.0244 - val_accuracy: 0.9933\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0228 - val_accuracy: 0.9937\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.0251 - val_accuracy: 0.9928\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.0302 - val_accuracy: 0.9918\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 93s 2ms/sample - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.0316 - val_accuracy: 0.9926\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 89s 1ms/sample - loss: 0.0101 - accuracy: 0.9967 - val_loss: 0.0239 - val_accuracy: 0.9938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f05c9167610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model with input images and labels\n",
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          validation_data=(x_test, y_test),\n",
    "          epochs=20,\n",
    "          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 99.4%\n"
     ]
    }
   ],
   "source": [
    "# model accuracy on test dataset\n",
    "score = model.evaluate(x_test,\n",
    "                       y_test,\n",
    "                       batch_size=batch_size,\n",
    "                       verbose=0)\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo con dos ramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Flatten, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical, plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train), (x_test,y_test) = mnist.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforma labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(unique(y_train))\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adecua los datos de entrda: reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = x_train.shape[1]\n",
    "x_train.reshape([-1,image_size,image_size,1])\n",
    "x_test.reshape([-1,image_size,image_size,1])\n",
    "\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "\n",
    "input_shape = (image_size, image_size,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parámetros de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net parameters\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "kernel_size = 3\n",
    "n_filters = 32\n",
    "dropout = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diseña las dos ramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#left branch\n",
    "left_inputs = Input(shape=input_shape)\n",
    "x = left_inputs\n",
    "filters = n_filters\n",
    "\n",
    "for i in range(3):\n",
    "    x = Conv2D(filters= filters,\n",
    "              kernel_size=kernel_size,\n",
    "              padding='same',\n",
    "              activation='relu')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = MaxPooling(x,2)(x)\n",
    "    filters*=2\n",
    "\n",
    "#right branch\n",
    "right_inputs = Input(shape=input_shape)\n",
    "y = right_inputs\n",
    "filters = n_filters\n",
    "\n",
    "for i in range(3):\n",
    "    y = Conv2D(filters= filters,\n",
    "              kernel_size=kernel_size,\n",
    "              padding='same',\n",
    "              activation='relu'\n",
    "              dilation=2)(y) # defect =1\n",
    "    y = Dropout(dropout)(y)\n",
    "    y = MaxPooling(x,2)(y)# defect=2\n",
    "    filters*=2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mezcla las dos ramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the branches\n",
    "y = concatenate([x,y])\n",
    "#\n",
    "y = Flattent()(y)\n",
    "y= Dropout(dropot)(y)\n",
    "outputs = Dense(num_labels, activation='softmax')(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crea el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build\n",
    "model = Model(inputs, outputs)\n",
    "#summary and plot\n",
    "model.summary()\n",
    "plot_model(model'cnn_model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compila"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimize ='adam',\n",
    "             metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit([x_train],\n",
    "                   y_train,\n",
    "                  validation_data= ([x_test],y_test)\n",
    "                  epochs= epochs, \n",
    "                  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate([x_test],y_test, \n",
    "                       batch_size=batch_size,\n",
    "                       verbose =0, )\n",
    "\n",
    "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el modelo ambas ramas tienen el mismo tamaño de kernel de 3, la rama derecha usa una tasa de dilatación de 2. \n",
    "\n",
    "\n",
    "La figura muestra el efecto de diferentes tasas de dilatación en un kernel con tamaño 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"./Imagenes/dilation.png\" width=\"800\" height=\"600\" align=\"center\"/>\n",
    "</center>\n",
    "<figcaption>\n",
    "<p style=\"text-align:center\">Dilatación de kernels</p>\n",
    "</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea es que al aumentar el tamaño de receptividad efectiva  del kernel utilizando la tasa de dilatación, la CNN permitirá a la rama correcta aprender diferentes mapas de características. El uso de una tasa de dilatación mayor que 1 es un método aproximado computacionalmente eficiente para aumentar el tamaño del campo receptivo. Es aproximado ya que el núcleo no es en realidad un núcleo completo. Es eficiente ya que utilizamos el mismo número de operaciones que con una tasa de dilatación igual a 1.\n",
    "\n",
    "Para apreciar el concepto del campo receptivo, observe que cuando el núcleo calcula cada punto de un mapa de características (features), su entrada es un parche en el mapa de características de la capa anterior que también depende de su mapa de características de la capa anterior. Si continuamos rastreando esta dependencia hasta la imagen de entrada, el núcleo depende de un parche de imagen llamado campo receptivo.\n",
    " \n",
    "Usaremos la opción *padding = 'same'* para asegurarnos de que no tendremos dimensiones negativas del tensor cuando se use el CNN dilatado. Al usar *padding = 'same'*, mantendremos las dimensiones de la entrada igual que los mapas de características de salida. Esto se logra rellenando la entrada con ceros para asegurarse de que la salida tenga el mismo tamaño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
