{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center'>Diferenciación Automática con Tensorflow 2.1</h1> \n",
    "\n",
    "<h3>Autor</h3>\n",
    "\n",
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "\n",
    "<h3>Fork</h3>\n",
    "\n",
    "<h3>Referencias</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Introducción </h2>\n",
    "\n",
    "[La diferenciación automática](https://en.wikipedia.org/wiki/Automatic_differentiation)\n",
    "es una técnica clave para la optimización de modelos de aprendizaje de máquinas (machine learning). En este cuaderno se hace una breve descripción de <a href=\"https://www.tensorflow.org/api_docs/python/tf/GradientTape\">tf.GradientTape</a> la API para diferenicación automática en tensorflow 2.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Gradient Tapes </h2>\n",
    "\n",
    "Lo que hace el *administrador de contexto* **tf.GradientTape** es calcular el gradiente de un cálculo con respecto a sus variables de entrada. Tensorflow registra todas las operaciones ejecutadas dentro del contexto de un tf.GradientTape en una cinta. Tensorflow usa esa cinta y los gradientes asociados con cada operación registrada para calcular los gradientes de un cálculo registrado usando el [modo de diferenciación hacia automática atrás](https://en.wikipedia.org/wiki/Automatic_differentiation)\n",
    "\n",
    "\n",
    "Las operaciones se registran si se ejecutan dentro de este administrador de contexto y al menos una de sus entradas está siendo *observada* (watched). Si una variable es creada con *tf.Variable*  es marcada como entrenable, será observada (registrada).\n",
    "\n",
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de Tensorflow:  2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Versión de Tensorflow: \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.ones((2,2))\n",
    "\n",
    "# this is the GradientTape context\n",
    "with tf.GradientTape() as t:\n",
    "    t.watch(x)\n",
    "    y = tf.reduce_sum(x)\n",
    "    z = tf.multiply(y,y)\n",
    "    \n",
    "# Derivate of z with respect to the original input tensor x\n",
    "dz_dx = t.gradient(z,x)\n",
    "for i in [0,1]:\n",
    "    for j in [0,1]:\n",
    "        assert dz_dx[i][j].numpy() == 8.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that matemáticamente lo que hicimos es lo siguiente:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "x = \\begin{pmatrix} 1 & 1\\\\1 & 1 \\end{pmatrix}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "y &= x_{11} + x_{12} + x_{21} + x_{22} = 4\\\\\n",
    "z &= y^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "La derivada es calculada usando la regla de la cadena.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{dz}{dx} = \\left( \\frac{dz}{dy}\\right) \\left( \\frac{dy}{dx}\\right) = 2yx= 8 x = \\begin{pmatrix} 8 & 8\\\\8 & 8 \\end{pmatrix}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=13, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[8., 8.],\n",
       "       [8., 8.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8., 8.],\n",
       "       [8., 8.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dz_dx.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible obtener gradientes de la salida (output) con respecto a valores intermedios  computados en un contexto tf.GradientTape *registrado*. Por defecto, los recursos mantenidos por GradientTape, son liberados tan pronto el método *GradientTape.gradient()* es llamado. Para hacer multiples llamados es necesario crear las instancia de GradientTape en modo persistente. Cuando ya no se requiere más, se recomienda liberar el recurso. Veamos el ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108.0\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape(persistent=True) as t:\n",
    "    t.watch(x)\n",
    "    y = x * x\n",
    "    z = y *  y\n",
    "dz_dx = t.gradient(z,x) # 108.0 (4*x³) evaluate at x=3.0\n",
    "dy_dx = t.gradient(y,x) #  6.0\n",
    "del t # delete the reference to the tape ( free the resource)\n",
    "print(dz_dx.numpy())\n",
    "print(dy_dx.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Registro del flujo de control  </h2>\n",
    "\n",
    "Debido a que las cintas (tapes) registran operaciones tal como ellas son ejecutadas, sentencias Python para el control del flujo (por ejemplo *if s* and *while s*) pueden ser manejadas de  manera natural:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,y):\n",
    "    output = 1.0\n",
    "    for i in range(y):\n",
    "        if i > 1 and i < 5:\n",
    "            output = tf.multiply(output,x)\n",
    "    return output\n",
    "\n",
    "def grad(x,y):\n",
    "    with tf.GradientTape() as t:\n",
    "        t.watch(x)\n",
    "        out = f(x,y)\n",
    "    return t.gradient(out,x)\n",
    "\n",
    "x = tf.convert_to_tensor(2.0)\n",
    "\n",
    "assert grad(x,6).numpy() == 12.0\n",
    "assert grad(x,5).numpy() == 12.0\n",
    "assert grad(x,4).numpy() == 4.0\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Gradientes de órdenes superiores   </h2>\n",
    "\n",
    "\n",
    "Las operaciones dentro del administrador de contexto *GradientTape* se registran para la diferenciación automática. Si los gradientes de órdenes superiores  se calculan en ese contexto, el cálculo del gradiente también se registra. Como resultado, la misma API también funciona para gradientes de orden superior. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(1.0) # Creates a Tensorflow variable intialized to 1.0\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "    with tf.GradientTape() as t2:\n",
    "        y = x * x * x\n",
    "    # Compute the gradient inside the 't' context manager\n",
    "    # which means the gradient computation is differentiable as well.\n",
    "    dy_dx = t2.gradient(y,x)\n",
    "d2y_d2x = t.gradient(dy_dx,x)\n",
    "\n",
    "assert dy_dx.numpy() == 3.0\n",
    "assert d2y_d2x.numpy() == 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
